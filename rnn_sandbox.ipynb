{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samirantonio/anaconda/envs/python3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import io\n",
    "from datetime import datetime\n",
    "from data_generator import DataGenerator\n",
    "from trade_env import TraderEnv\n",
    "from rnn.model_keras import NeuralNetwork\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DataGenerator(random=False, first_index=10)\n",
    "dt.rewind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode input data\n",
    "def onehot_encoded (integer_encoded, char_to_int = 3):\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    letter = [0 for _ in range(char_to_int)]\n",
    "    letter[integer_encoded] = 1\n",
    "    onehot_encoded.append(letter)\n",
    "    \n",
    "    return onehot_encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_price = 0\n",
    "last_time = 0\n",
    "steps = 100\n",
    "def get_state(raw_state):\n",
    "    global last_price\n",
    "    global last_time\n",
    "    list = []\n",
    "\n",
    "    price = raw_state[\"price\"]\n",
    "\n",
    "    def prepare_orders(orders, price, multi):\n",
    "        for order in orders:\n",
    "            list.append((float(order[0])/price) * multi)\n",
    "            #list.append(float(order[1]))\n",
    "\n",
    "    bids = raw_state[\"bids\"][:5]\n",
    "    asks = raw_state[\"asks\"][:5]\n",
    "    prepare_orders(bids, price, 1)\n",
    "    prepare_orders(asks, price, -1)\n",
    "\n",
    "\n",
    "    if last_price != 0:\n",
    "        list.extend([price/last_price])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "        \n",
    "    \n",
    "    if last_time != 0:\n",
    "        list.extend([int(state['timestamp'])/last_time])\n",
    "    else:\n",
    "        list.extend([0])\n",
    "        \n",
    "    last_time = int(state['timestamp'])\n",
    "    \n",
    "    y = dt.get_from_index(dt.index + steps)[\"price\"]\n",
    "    \n",
    "    if y > price:\n",
    "        y = onehot_encoded(0)\n",
    "    elif y < price: \n",
    "        y = onehot_encoded(2)\n",
    "    else:\n",
    "        y = onehot_encoded(1)\n",
    "        \n",
    "    #datetime.fromtimestamp(int(state['timestamp']))\n",
    "    \n",
    "    return [list, y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 12)\n",
      "(30000, 3)\n"
     ]
    }
   ],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "while len(trainX) < 30000: #(dt.max_steps() - steps*3):\n",
    "    state = dt.next()\n",
    "    state = get_state(state)\n",
    "    trainX.append(state[0])\n",
    "    trainY.append(state[1])\n",
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data, features, batch_size, seq_length):\n",
    "    int_text = np.array(data)\n",
    "    \n",
    "    n_batches = int(len(data) / (batch_size * seq_length))\n",
    "\n",
    "    xdata = np.array(data[: n_batches * batch_size * seq_length])\n",
    "    \n",
    "    data = xdata.reshape(-1, seq_length, features)\n",
    "    \n",
    "    #step1 = xdata.reshape(batch_size, -1)\n",
    "    \n",
    "    #print (step1.shape)\n",
    "    #data = np.split(step1, n_batches, 1)\n",
    "    \n",
    "    return np.array(list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 12)\n",
      "(3000, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "batch_size = 1000\n",
    "seq_length = 10\n",
    "xdata = get_batches(trainX, trainX.shape[1], batch_size, seq_length)\n",
    "print(xdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3)\n",
      "(3000, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "ydata = get_batches(trainY, trainY.shape[1], batch_size, seq_length)\n",
    "#ydata = ydata.reshape(9900, seq_length, 3)\n",
    "print(ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_reshaped = []\n",
    "for i in range(ydata.shape[0]):\n",
    "    y_train_reshaped.append(ydata[i, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3)\n"
     ]
    }
   ],
   "source": [
    "y_train_reshaped = np.array(y_train_reshaped)\n",
    "print(y_train_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(0.00001, xdata.shape[2], y_train_reshaped.shape[1], xdata.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2100 samples, validate on 900 samples\n",
      "Epoch 1/150\n",
      "2100/2100 [==============================] - 3s 1ms/step - loss: 0.7928 - mean_absolute_error: 0.3486 - acc: 0.5086 - val_loss: 0.7096 - val_mean_absolute_error: 0.3275 - val_acc: 0.6400\n",
      "Epoch 2/150\n",
      "2100/2100 [==============================] - 1s 674us/step - loss: 0.7705 - mean_absolute_error: 0.3444 - acc: 0.5038 - val_loss: 0.7358 - val_mean_absolute_error: 0.3402 - val_acc: 0.6400\n",
      "Epoch 3/150\n",
      "2100/2100 [==============================] - 1s 666us/step - loss: 0.7650 - mean_absolute_error: 0.3431 - acc: 0.5076 - val_loss: 0.7202 - val_mean_absolute_error: 0.3336 - val_acc: 0.6400\n",
      "Epoch 4/150\n",
      "2100/2100 [==============================] - 1s 658us/step - loss: 0.7657 - mean_absolute_error: 0.3421 - acc: 0.5176 - val_loss: 0.7439 - val_mean_absolute_error: 0.3445 - val_acc: 0.6400\n",
      "Epoch 5/150\n",
      "2100/2100 [==============================] - 1s 667us/step - loss: 0.7610 - mean_absolute_error: 0.3438 - acc: 0.5043 - val_loss: 0.7173 - val_mean_absolute_error: 0.3315 - val_acc: 0.6400\n",
      "Epoch 6/150\n",
      "2100/2100 [==============================] - 1s 660us/step - loss: 0.7649 - mean_absolute_error: 0.3430 - acc: 0.5071 - val_loss: 0.7267 - val_mean_absolute_error: 0.3376 - val_acc: 0.6400\n",
      "Epoch 7/150\n",
      "2100/2100 [==============================] - 2s 739us/step - loss: 0.7644 - mean_absolute_error: 0.3429 - acc: 0.5138 - val_loss: 0.7223 - val_mean_absolute_error: 0.3352 - val_acc: 0.6400\n",
      "Epoch 8/150\n",
      "2100/2100 [==============================] - 2s 738us/step - loss: 0.7635 - mean_absolute_error: 0.3428 - acc: 0.5138 - val_loss: 0.7312 - val_mean_absolute_error: 0.3390 - val_acc: 0.6400\n",
      "Epoch 9/150\n",
      "2100/2100 [==============================] - 2s 748us/step - loss: 0.7646 - mean_absolute_error: 0.3433 - acc: 0.4981 - val_loss: 0.7185 - val_mean_absolute_error: 0.3332 - val_acc: 0.6400\n",
      "Epoch 10/150\n",
      "2100/2100 [==============================] - 2s 726us/step - loss: 0.7584 - mean_absolute_error: 0.3425 - acc: 0.5152 - val_loss: 0.7315 - val_mean_absolute_error: 0.3370 - val_acc: 0.6400\n",
      "Epoch 11/150\n",
      "2100/2100 [==============================] - 1s 711us/step - loss: 0.7611 - mean_absolute_error: 0.3426 - acc: 0.5048 - val_loss: 0.7277 - val_mean_absolute_error: 0.3361 - val_acc: 0.6400\n",
      "Epoch 12/150\n",
      "2100/2100 [==============================] - 1s 708us/step - loss: 0.7586 - mean_absolute_error: 0.3420 - acc: 0.5224 - val_loss: 0.7194 - val_mean_absolute_error: 0.3324 - val_acc: 0.6400\n",
      "Epoch 13/150\n",
      " 928/2100 [============>.................] - ETA: 0s - loss: 0.7642 - mean_absolute_error: 0.3424 - acc: 0.5108"
     ]
    }
   ],
   "source": [
    "nn.train(xdata, y_train_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt.index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
